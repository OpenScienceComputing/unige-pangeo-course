{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Julius Busecke's 2023 AMS Live Demo\n",
    "\"Reproducible Science in the Cloud with Pangeo Tools\"\n",
    "[Video of the AMS talk (16min)](https://ams.confex.com/ams/103ANNUAL/videogateway.cgi/id/552040?recordingid=552040)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from distributed import Client\n",
    "#client = Client()\n",
    "#client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a Dask Gateway Cluster on Nebari \n",
    "import sys, os\n",
    "\n",
    "group = 'pangeo'\n",
    "aws_profile = 'osn-esip'\n",
    "aws_region = 'none'\n",
    "endpoint_url = f's3.{aws_region}.amazonaws.com'\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['HOME'],'shared',group,'nebari-setup','lib'))\n",
    "import nebari_tools as nbt\n",
    "\n",
    "nbt.set_credentials(profile=aws_profile, region=aws_region, endpoint_url=endpoint_url)\n",
    "\n",
    "worker_max = 10\n",
    "\n",
    "client, cluster = nbt.start_dask_cluster(profile=aws_profile, worker_max=worker_max, \n",
    "                                      region=aws_region, use_existing_cluster=True,\n",
    "                                      adaptive_scaling=True, wait_for_cluster=True, \n",
    "                                      worker_profile='Small Worker', \n",
    "                                      propagate_env=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tic = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xmip.preprocessing import combined_preprocessing\n",
    "from xmip.utils import google_cmip_col\n",
    "\n",
    "from xarrayutils.plotting import shaded_line_plot\n",
    "xr.set_options(keep_attrs=True)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "plt.rcParams['figure.figsize'] = (10,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Load CMIP6 data from Pangeo Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "col = google_cmip_col()\n",
    "query = dict(\n",
    "    source_id = [\n",
    "     'IPSL-CM6A-LR',\n",
    "     'MPI-ESM1-2-LR',\n",
    "     'GFDL-ESM4',\n",
    "     'EC-Earth3',\n",
    "     'CMCC-ESM2',\n",
    "     'CESM2',\n",
    "    ],\n",
    "    experiment_id = ['historical','ssp126', 'ssp370', 'ssp245', 'ssp585'],\n",
    "    grid_label='gn',\n",
    ")\n",
    "cat = col.search(\n",
    "    **query,\n",
    "    variable_id='tos',\n",
    "    member_id=['r1i1p1f1',],#'r2i1p1f1'\n",
    "    table_id='Omon'\n",
    ")\n",
    "kwargs = dict(preprocess=combined_preprocessing, xarray_open_kwargs=dict(use_cftime=True), aggregate=False)\n",
    "ddict = cat.to_dataset_dict(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_area = col.search(\n",
    "    **query,\n",
    "    table_id='Ofx',\n",
    "    variable_id='areacello',\n",
    ")\n",
    "ddict_area = cat_area.to_dataset_dict(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Postprocess loaded data with xmip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmip.postprocessing import match_metrics\n",
    "ddict_w_area = match_metrics(ddict, ddict_area, 'areacello', print_statistics=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xmip.postprocessing import concat_members\n",
    "\n",
    "ddict_trimmed = {k:ds.sel(time=slice(None, '2100')) for k,ds in ddict_w_area.items()}\n",
    "ddict_combined_members = concat_members(\n",
    "    ddict_w_area,\n",
    "    concat_kwargs = {'coords':'minimal', 'compat':'override', 'join':'override'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Organize datasets in xarray-datatree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datatree import DataTree\n",
    "\n",
    "# create a path: dataset dictionary, where the path is based on each datasets attributes\n",
    "tree_dict = {f\"{ds.source_id}/{ds.experiment_id}/\":ds for ds in ddict_combined_members.values()}\n",
    "\n",
    "dt = DataTree.from_dict(tree_dict)\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.nbytes / 1e9  # size in GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Select a single member that is present in each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_single_member = DataTree()\n",
    "for model_name, model in dt.children.items():\n",
    "    member_id_values = []\n",
    "    for experiment_name, experiment in model.children.items():\n",
    "        ds = experiment.ds\n",
    "        member_id_values.append(set(ds.member_id.data))  \n",
    "    \n",
    "    # find the intersection of all values\n",
    "    # print(member_id_values)\n",
    "    full_members = set(member_id_values[0]).intersection(*member_id_values)\n",
    "    # sort and take the first one\n",
    "    pick_member = sorted(full_members)[0]\n",
    "    dt_single_member[model_name] = model.sel(member_id=pick_member)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Compute weighted global mean SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average temperature globally\n",
    "def global_mean_sst(ds):\n",
    "    return ds.tos.weighted(ds.areacello.fillna(0)).mean(['x', 'y']).persist() \n",
    "\n",
    "timeseries = dt_single_member.map_over_subtree(global_mean_sst)\n",
    "timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "timeseries['/IPSL-CM6A-LR/ssp585'].ds['tos'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Compute anomaly to 1950-1980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_ref_value(ds):\n",
    "    return ds.sel(time=slice('1950','1980')).mean('time')\n",
    "\n",
    "anomaly = DataTree()\n",
    "for model_name, model in timeseries.children.items():\n",
    "    # model-specific base period\n",
    "    base_period = get_ref_value(model[\"historical\"].ds)\n",
    "    anomaly[model_name] = model - base_period   # subtree - Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_time(ds):\n",
    "    start_date = ds.time.data[0]\n",
    "    new_time = xr.cftime_range(f\"{start_date.year}-{start_date.month:02}\", freq='1MS', periods=len(ds.time))\n",
    "    ds_new_cal = ds.assign_coords(time=new_time, source_id=model_name)\n",
    "    return ds_new_cal\n",
    "    \n",
    "\n",
    "experiment_dict = {k:[] for k in ['historical','ssp126', 'ssp370', 'ssp245', 'ssp585']}\n",
    "\n",
    "for model_name, model in anomaly.children.items():\n",
    "    for experiment_name, experiment in model.children.items():\n",
    "        # replace the time dimension\n",
    "        ds_new_cal = replace_time(experiment.ds)\n",
    "        experiment_dict[experiment_name].append(ds_new_cal.load())\n",
    "\n",
    "# concatenate all models for a given experiment\n",
    "plot_dict = {k:xr.concat(ds_lst, dim='source_id') for k, ds_lst in experiment_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Load observational dataset (thanks [pangeo-forge](https://pangeo-forge.org)!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = 'https://ncsa.osn.xsede.org/Pangeo/pangeo-forge/HadISST-feedstock/hadisst.zarr'\n",
    "ds_obs = xr.open_dataset(store, engine='zarr', chunks={}).rename({'sst':'tos'}).convert_calendar('standard', use_cftime=True)\n",
    "\n",
    "# mask missing values\n",
    "ds_obs = ds_obs.where(abs(ds_obs.tos)<50)\n",
    "\n",
    "# reconstruct area\n",
    "area = np.cos(np.deg2rad(ds_obs.latitude)) * 110e3 **2\n",
    "\n",
    "# Repeat same steps from above\n",
    "ds_obs_ts = ds_obs.weighted(area).mean(['longitude', 'latitude'])\n",
    "ds_obs_anomaly = ds_obs_ts - get_ref_value(ds_obs_ts)\n",
    "\n",
    "# add to plot_dict\n",
    "plot_dict['observations'] = ds_obs_anomaly.expand_dims(['source_id', 'dcpp_init_year']).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Here it is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "color_dict = {\n",
    "    'historical':'0.5',\n",
    "    'ssp126': 'C2',\n",
    "    'ssp245': 'gold',\n",
    "    'ssp370': 'C1',\n",
    "    'ssp585': 'C3',\n",
    "    'observations': 'C5'\n",
    "}\n",
    "for experiment, ds in plot_dict.items():\n",
    "    color = color_dict[experiment]\n",
    "    smooth = ds['tos'].sel(time=slice(None, '2100')).rolling(time=2*12).mean().squeeze('dcpp_init_year')\n",
    "    lw = 2 if experiment=='observations' else 1.5\n",
    "    shaded_line_plot(smooth, 'source_id', ax=ax, spreads=[2.0], alphas=[0.2], line_kwargs=dict(color=color, label=f\"{experiment} ({len(ds.source_id)})\", lw=lw))\n",
    "plt.legend(loc=2);\n",
    "plt.grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = time.time()\n",
    "print(f\"Elapsed time: {int(toc-tic)} seconds\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "global-global-pangeo",
   "language": "python",
   "name": "conda-env-global-global-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
