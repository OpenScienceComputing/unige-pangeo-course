{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Accessing Sentinel-3 OLCI data with the Planetary Computer STAC API\n",
    "\n",
    "The [Sentinel 3 OLCI instrument](https://sentinel.esa.int/web/sentinel/technical-guides/sentinel-3-olci) provides radiance measurements of the Earth's surface in the visible and near infra-red spectral domain.\n",
    "These measurements are processed into two Level 2 products, one for the ocean and one for the land.\n",
    "Each product has its own STAC collection in the Planetary Computer:\n",
    "\n",
    "- Land: `sentinel-3-olci-lfr-l2-netcdf`\n",
    "- Ocean: `sentinel-3-olci-wfr-l2-netcdf`\n",
    "\n",
    "This notebook demonstrates accessing and visualizing data from both collections.\n",
    "\n",
    "### Data Access\n",
    "\n",
    "This notebook works with or without an API key, but you will be given more permissive access to the data with an API key. If you are using the [Planetary Computer Hub](https://planetarycomputer.microsoft.com/compute) to run this notebook, then your API key is automatically set to the environment variable `PC_SDK_SUBSCRIPTION_KEY` for you when your server is started. Otherwise, you can view your keys by signing in to the [developer portal](https://planetarycomputer.developer.azure-api.net/). The API key may be manually set via the environment variable `PC_SDK_SUBSCRIPTION_KEY` or the following code:\n",
    "\n",
    "```python\n",
    "import planetary_computer\n",
    "planetary_computer.settings.set_subscription_key(<YOUR API Key>)\n",
    "```\n",
    "\n",
    "The datasets hosted by the Planetary Computer are available in [Azure Blob Storage](https://docs.microsoft.com/en-us/azure/storage/blobs/). We'll use [pystac-client](https://pystac-client.readthedocs.io/) to search the Planetary Computer's [STAC API](https://planetarycomputer.microsoft.com/api/stac/v1/docs) for the subset of the data that we care about, and then we'll load the data directly from Azure Blob Storage. We'll specify a `modifier` so that we can access the data stored in the Planetary Computer's private Blob Storage Containers. See [Reading from the STAC API](https://planetarycomputer.microsoft.com/docs/quickstarts/reading-stac/) and [Using tokens for data access](https://planetarycomputer.microsoft.com/docs/concepts/sas/) for more.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Secrets for writing to the ESIP OSN \"s3://esip\" Bucket\n",
    "osn_keys = '/shared/pangeo/nebari-setup/osn_keys.env'\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv(osn_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Water products\n",
    "\n",
    "The collection description tells us more about the water products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import planetary_computer\n",
    "import pystac_client\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")\n",
    "collection = catalog.get_collection(\"sentinel-3-olci-wfr-l2-netcdf\")\n",
    "display(Markdown(f\"### {collection.id}\\n\\n{collection.description}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Define the area of interest and search the water collection\n",
    "\n",
    "We'll search for items over the coordinates `[-2.79, 44.14]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import fsspec\n",
    "\n",
    "search = catalog.search(\n",
    "    collections=[\"sentinel-3-olci-wfr-l2-netcdf\"],\n",
    "    intersects={\"type\": \"Point\", \"coordinates\": [-2.79, 44.14]},\n",
    ")\n",
    "item = next(search.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in search.items():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Available Assets and Metadata\n",
    "\n",
    "Each item includes a handful of assets linking to NetCDF files with the data or additional metadata files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import rich.table\n",
    "\n",
    "t = rich.table.Table(\"Key\", \"Value\")\n",
    "for key, asset in item.assets.items():\n",
    "    t.add_row(key, asset.description)\n",
    "\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Reading data\n",
    "\n",
    "We can use xarray to read each NetCDF file directly from Blob Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "item.assets['par']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "keys = [\n",
    "    \"iwv\",\n",
    "    \"par\",\n",
    "    \"trsp\",\n",
    "    \"w-aer\",\n",
    "    \"chl-nn\",\n",
    "    \"iop-nn\",\n",
    "    \"tsm-nn\",\n",
    "    \"chl-oc4me\",\n",
    "    \"oa01-reflectance\",\n",
    "]\n",
    "datasets = [xr.open_dataset(fsspec.open(item.assets[k].href).open()) for k in keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ds = xr.combine_by_coords(datasets, join=\"exact\", combine_attrs=\"drop_conflicts\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "We'll plot the integrated water vapor variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ds.IWV.coarsen({\"rows\": 10, \"columns\": 10}, boundary=\"trim\").mean().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Geolocating the data\n",
    "\n",
    "The geospatial information in this dataset is distributed as a separate NetCDF file, cataloged under the `geoCoordinates` key. That contains a dataset with `latitude` and `longitude` arrays, each of which is the same shape as the data variables and gives the latitude and longitude for each pixel in data variable.\n",
    "\n",
    "We'll reshape the data to a (long-form) DataFrame with a single row for each pixel. We'll then make a scatter plot, using the longitude and latitude as the `x` and `y` coordintes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datashader\n",
    "import colorcet\n",
    "\n",
    "geo = xr.open_dataset(fsspec.open(item.assets[\"geo-coordinates\"].href).open()).load()\n",
    "a01 = ds.Oa01_reflectance.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsgeo = xr.combine_by_coords([geo, a01], join=\"exact\", combine_attrs=\"drop_conflicts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsgeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsgeo = dsgeo.set_coords((\"latitude\", \"longitude\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsgeo['Oa01_reflectance'].hvplot.quadmesh(x='longitude', y='latitude', geo=True, rasterize=True, tiles='OSM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"longitude\": geo.longitude.data.ravel(),\n",
    "        \"latitude\": geo.latitude.data.ravel(),\n",
    "        \"value\": a01.data.ravel(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "To avoid overplotting the data, we'll use [datashader](https://datashader.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "cvs = datashader.Canvas(plot_width=600, plot_height=600)\n",
    "agg = cvs.points(df, \"latitude\", \"longitude\", agg=datashader.reductions.mean(\"value\"))\n",
    "img = datashader.tf.shade(agg, cmap=colorcet.CET_CBD2)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Land data\n",
    "\n",
    "Let's do the same process, but for the land product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "collection = catalog.get_collection(\"sentinel-3-olci-lfr-l2-netcdf\")\n",
    "display(Markdown(f\"### {collection.id}\\n\\n{collection.description}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "search = catalog.search(\n",
    "    collections=[\"sentinel-3-olci-lfr-l2-netcdf\"],\n",
    "    intersects={\"type\": \"Point\", \"coordinates\": [-2.79, 44.14]},\n",
    ")\n",
    "item = next(search.items())\n",
    "t = rich.table.Table(\"Key\", \"Value\")\n",
    "for key, asset in item.assets.items():\n",
    "    t.add_row(key, asset.description)\n",
    "\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Plot FAPAR\n",
    "\n",
    "The green instantaneous Fraction of Absorbed Photosynthetically Active Radiation (FAPAR) product uses a [vegetation index algorithm](https://sentinel.esa.int/web/sentinel/technical-guides/sentinel-3-olci/level-2/olci-global-vegetation-index) to provide an estimate of the FARAR in the plant canopy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dataset = xr.open_dataset(fsspec.open(item.assets[\"gifapar\"].href).open())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "geo = xr.open_dataset(fsspec.open(item.assets[\"geo-coordinates\"].href).open()).load()\n",
    "fapar = dataset.GIFAPAR.load()\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"longitude\": geo.longitude.data.ravel(),\n",
    "        \"latitude\": geo.latitude.data.ravel(),\n",
    "        \"value\": fapar.data.ravel(),\n",
    "    }\n",
    ")\n",
    "cvs = datashader.Canvas(plot_width=600, plot_height=600)\n",
    "agg = cvs.points(df, \"latitude\", \"longitude\", agg=datashader.reductions.mean(\"value\"))\n",
    "img = datashader.tf.shade(agg, cmap=colorcet.CET_CBD2)\n",
    "img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global-global-pangeo",
   "language": "python",
   "name": "conda-env-global-global-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
